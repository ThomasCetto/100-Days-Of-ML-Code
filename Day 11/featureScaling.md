# Feature scaling

Feature scaling is important because it make sure that every feature has the right weight in the model training. That's because if feature x has a range that goes from 0 to 100.000, it will have a bigger influence than feature y that goes from 0 to 30.

To solve this problem we have to normalize the values of both variables, and it can be made with different techniques:
- maximum absolute scaling
- min-max feature scaling
- z-score method
- Robust scaling

